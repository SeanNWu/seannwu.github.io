
<!DOCTYPE html>
<html>
<head>
    <style>
      body {
        font-family: "Times New Roman", Times, serif;
        margin-left: 200px;
        margin-right: 200px;
        color: #333;
        line-height: 1.6;
      }
      h1, h2, h3, h4, h5, h6 {
        color: #444;
      }
      a {
        color: #0645AD;
        text-decoration: none;
      }
      a:hover {
        text-decoration: underline;
      }
      .content {
        display: flex; /* Use flexbox for horizontal alignment */
        align-items: flex-start; /* Align items to the top */
      }
      .content img {
        max-width: 30%; /* Limit the maximum width to 30% of container */
        max-height: 100%; /* Limit the maximum height to container's height */
        width: auto; /* Allow width to adjust while maintaining aspect ratio */
        height: auto; /* Allow height to adjust while maintaining aspect ratio */
        padding: 10px; /* Add some spacing between images */
        margin-right: 20px; /* Add some spacing to the right of the image */
      }
      .description {
        flex-grow: 1; /* Allow the description to take up the remaining space */
      }
      /* Empty line with padding */
      .empty-line {
        height: 20px; /* Adjust the height as needed */
      }
    </style>
</head>
<body>
    <div class="empty-line"></div> <!-- Empty line -->
    <div class="content">
        <img src="Wu_Columbia.JPG" alt="Image 1" class="profile">
        <div class="description">
           <p> My name is Sean Wu, and I am an undergraduate student at Pepperdine studying computer science and mathematics. I am advised by <a href="https://web.cs.ucla.edu/~fab/">Dr. Fabien Scalzo</a>. My research interests are computer vision and natural language processing, specifically their applications in medicine.</p>
           <p>At UCLA I am advised by Dr. Ira B. Kurtz for NLP in Nephrology, and Dr. Kouros Nouri Mahdavi in the Glaucoma Artificial Intelligence Lab.</p>

            <p>
                <a href="mailto:sean.wu@pepperdine.edu">Email</a> / 
                <a href="https://seannwu.github.io/SeanWu/Sean_Wu_Website_Resume.pdf">CV</a> / 
                <a href="https://scholar.google.com/citations?user=Z7Ul8jUAAAAJ&hl=en&oi=sra">Google Scholar</a>
            </p>
        </div>
    </div>
    <br>
    
    <h2>Awards and Honors</h2>
<table cellspacing="10">
  <tr>
    <td><img src="11.png" width="180" height="108"></td>
    <td>Named one of 413 Scholars out of estimated pool of over 5,000 college sophomores and juniors, highlighting exceptional aptitude and potential for a research career in natural sciences, engineering, and mathematics. See <a href="https://goldwaterscholarship.gov/">Goldwater Scholarship Website</a>.</td>
  </tr>
     <tr>
    <td><img src="OIP.jpeg" width="180" height="90"></td>
    <td>Computing Research Association Oustanding Undergraduate Researcher Honorable Mention 2024 See <a href="https://cra.org/about/awards/outstanding-undergraduate-researcher-award/">CRA Website</a>.</td>
  </tr>
  <tr>
    <td><img src="10.png" width="180" height="108""></td>
    <td>Summer 2023: I was a research fellow at Amazon SURE @ Columbia University, where conducted research under Simon Billinge. Check out the program details here: <a href="https://www.amazon.science/sure">Amazon Science Website</a></td>
  </tr>
  <tr>
    <td><img src="northrop.png" width="180" height="90"></td>
    <td>Awarded the Northrop Grumman Endowed Scholarship for outstanding computer science student.</td>
  </tr>
  <tr>
    <td><img src="keck.png" width="180" height="70"></td>
    <td>Summer 2022: I was a part of the Keck Scholars Fellows program at Pepperdine where I conducted research during both the school year and the summer.</td>
  </tr>
</table>
    
    
    <h2>Research Projects</h2>
    
    <h3>Deep Learning in Ophthalmology</h3>
    <table cellspacing="10">
        <tr>
            <td>
                <img src="4.png" width="250" height="150">
            </td>
            <td>
                <b>Prediction of visual field progression with serial optic disc photographs using deep learning</b>
                <br>
                Vahid Mohammadzadeh, <i>Sean Wu</i>, Tyler Davis, Arvind Vepa, Esteban Morales, Sajad Besharati, Kiumars Edalati, Jack Martinyan, Mahshad Rafiee, Arthur Martynian, Fabien Scalzo, Joseph Caprioli, Kouros Nouri-Mahdavi, <i>British Journal of Ophthalmology</i> (2023).
                <br>
                <a href="https://bjo.bmj.com/content/early/2023/10/12/bjo-2023-324277.abstract">[Paper]</a>
            </td>
        </tr>
      <tr>
            <td>
                <img src="2.png" width="250" height="150">
            </td>
            <td>
                <b>Auxiliary-Domain Learning for a Functional Prediction of Glaucoma Progression</b>
                <br>
<i>Sean Wu</i>, Vahid Mohammadzadeh, Kiumars Edalati, Jack Martinyan, Arthur Martinyan, Joseph Caprioli, Kouros Nouri-Mahdavi, Fabien Scalzo, <i>International Workshop on Ophthalmic Medical Image Analysis</i> (pp. 21-31). Cham: Springer Nature Switzerland.           
                           <br>

                <a href="https://link.springer.com/chapter/10.1007/978-3-031-44013-7_3">[Paper]</a> <a href="https://www.youtube.com/watch?v=wTjczXUgteU">[Video]</a>

            </td>
        </tr>


      <tr>
            <td>
                <img src="3.png" width="250" height="150">
            </td>
            <td>
                <b>Prediction of Central Visual Field Measures From Macular OCT Volume Scans With Deep Learning</b>
                <br>
Vahid Mohammadzadeh*, Arvind Vepa*, Chuanlong Li, <i>Sean Wu</i>, Leila Chew, Golnoush Mahmoudinezhad, Evan Maltz, Serhat Sahin, Apoorva Mylavarapu, Kiumars Edalati, Jack Martinyan, Dariush Yalzadeh, Fabien Scalzo, Joseph Caprioli, Kouros Nouri-Mahdavi,<i>Translational Vision Science & Technology</i> 12, no. 11 (2023): 5-5.          
                           <br>

                <a href="https://tvst.arvojournals.org/article.aspx?articleid=2792982">[Paper]</a>

            </td>
        </tr>
<tr>
            <td>
                <img src="ARVO.png" width="250" height="150">
            </td>
            <td>
                <b>Prediction of visual field progression based on baseline and longitudinal structural measurements with a deep learning model</b>
                <br>
                Vahid Mohammadzadeh, <i>Sean Wu</i>, Tyler Davis, Arvind Vepa, Esteban Morales, Sajad Besharati, Kiumars Edalati, Jack Martinyan, Mahshad Rafiee, Arthur Martynian, Fabien Scalzo, Joseph Caprioli, Kouros Nouri-Mahdavi, <i>(Revisions) American Journal of Ophthalmology</i> (2024).
                           <br>

                <a href="">[Paper Out Soon!]</a>

            </td>
        </tr>

   <tr>
            <td>
                <img src="eye.png" width="250" height="150">
            </td>
            <td>
                <b>Using Artificial Intelligence for Evaluating Structural Eyelid Change Following Mϋller’s Muscle-Conjunctival Resection</b>
                <br>
Vahid Mohammadzadeh, <i>Sean Wu<i>, Persiana Saffari, Sean Ghiam, Fabien Scalzo, Maral Namdari, Kelsey Roelofs, Justin Karlin, Robert A Goldberg, Daniel B. Rootman, <i>American Society of Ophthalmic Plastic and Reconstructive Surgery (ASOPRS)<i> 54th Annual Fall Scientific Symposium, 2024                           <br>

                <a href="">[Paper Out Soon!]</a>

            </td>
        </tr>
     

       <tr>
        <td><img src="survival_curve.png" width="250" height="150"></td>
        <td>I conducted research on a deep survival analysis algorithm to predict future glaucoma progression and time to detect progression (TTP) from early visual field (VF) information using a deep learning (DL) model. The TTP was the date of the two consecutive visits. I designed a DL model to predict glaucoma progression from the threshold sensitivities at the 54 points of the first five VF visits. I paired a survival analysis with the DL model for predicting the TTP. The results showed that the mean of TTP was 3.4 years, the AUC for predicting future glaucoma progression was 0.81, and the R squared and mean absolute error between the actual and predicted TTP were 0.92 and 0.73 years, respectively. <b>(Accepted to AAO 2023)</b></td>
      </tr>
       <tr>
        <td><img src="multimodal.png" width="250" height="150"></td>
        <td>I participated in a research project that aimed to design a deep learning model for predicting the progression of glaucoma using a multimodal approach. I collaborated with other researchers to utilize a convolutional neural network pre-trained on ImageNet and incorporated baseline structural measures including disc photographs, retinal nerve fiber layer, and macular OCT measures as predictors. By combining all three imaging modalities, our model achieved a significantly higher performance for predicting progression with an AUC of 0.884 [0.834-0.934]. <b>(Accepted to AAO 2023)</b></td>
      </tr>
       <tr>
        <td><img src="gen_vf.png" width="250" height="150"></td>
        <td>The research project I worked on aimed to predict final visual field measurements using a deep learning model. We analyzed data from 7,150 glaucoma eyes with 5 or more VF visits and ≥3 years of follow-up, and developed a generative DL model that predicted mean deviation, pattern standard deviation, and threshold sensitivities at 54 VF locations using data from the first five VF exams. Our goal was to improve the prediction of final VF measurements and ultimately aid in the diagnosis and management of glaucoma. <b>(Accepted to AAO 2023)</b></td>
      </tr>
     <tr>
        <td><img src="masked.png" width="250" height="150"></td>
        <td>I led this research to denoise visual field data by employing self-supervised masked autoencoders, which outperformed previous approaches using variational autoencoders. We benchmarked our model using pointwise linear regression and other relevant visual field packages. <b>(Currently Writing Manuscript)</b></td>
      </tr>
    </table>
    
    <h3>Artificial Intelligence in Ecology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="6.png" width="250" height="150"></td>
        <td>I developed an automated process for classifying plant cells based on their type to expedite analysis and broaden the scope of questions that can be asked in anatomical studies of plant hydraulic traits. Our research evaluated a deep learning-based model that leveraged both cropped cell image input and contextual information from broader cropped images to accurately segregate plant cells. We found that using a second image input significantly improved the model's accuracy (98.1%), highlighting the importance of local context in accurately classifying cells. Our results suggest that this classifier could have future applications in automatic cell-type detection in xylem tissue image cross-sections. <b>(ISVC 2023)</b></td>
      </tr>
      <tr>
        <td><img src="PlantSeg.png" width="250" height="150"></td>
        <td>In this project, I constructed a deep convolutional neural network (DCNN) to segment and classify cell types in light micrographs. I created an encoder-decoder U-Net architecture using convolutional layers to encode features and transposed convolutional layers to upscale features to a vessel segmentation mask. I interleaved batch normalization and max pooling layers to provide strong regularization. For classification, I explored transformers and convolutional neural networks and achieved a 98.1% accuracy. The testing samples were isolated, and the DCNN performed vessel segmentation with high pixel classification accuracy (97.05%) and excellent precision score (80.71%). <b>(ESA 2023)</b> </td>
      </tr>
    </table>
    
    <h3>Natural Language Processing</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="NEJM.png" width="250" height="150"></td>
        <td>I lead a study exploring the capabilities of large language models (LLMs) in the context of medical knowledge, specifically focusing on internal medicine subspecialty multiple-choice tests. We compared the performance of various open-source LLMs against GPT-4 and Claude 2, using nephrology as a complex example. The results revealed that open-sourced LLMs achieved a success rate of 17.1% to 25.5%, while Claude 2 answered 54.4% correctly, and GPT-4 excelled with a 73.3% accuracy in answering nephSAP multiple-choice questions. These findings suggest that GPT-4 and Claude 2 outperformed open-sourced LLMs in zero-shot reasoning, highlighting their potential for enhancing subspecialty medical training and patient care through applications such as adaptive training, medical co-piloting, and digital physician-patient interactions.  <b>(Accepted to New England Journal of Medicine AI)</b></td>
      </tr>

    </table>
    
    <h3>Interventional Neurology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="Celebral.png" width="250" height="150"></td>
        <td>I developed a novel technique for reconstructing 3D images from biplane 2D angiographic images of the brain. By parameterizing the data and utilizing a 3D denoising auto-encoder, I achieved exceptional results with a pixel accuracy of 99.87% and an intersection over union score of 30.0%. These results surpassed previous generative methods, demonstrating the significance of volumization in achieving accurate visual correspondence. The proposed technique holds promise for clinical applications, offering a cost-effective and efficient tool for neurosurgeons to visualize and analyze angiograms of the brain. <b>(Accepted to ISVC 2023)</b></td>
      </tr>
    </table>
    
    <h3>Others</h3>
 <table cellspacing="10">
      <tr>
        <td><img src="8.png" width="250" height="150"></td>
        <td>In my research, I investigated the challenge of identifying salient regions in medical imaging using deep neural networks and transformer networks. By applying the theory of dictionary learning and analyzing gender classification in brain MRI, I trained models using ResNet 18 and visual transformers. Achieving an accuracy of 84% and 73% respectively, I observed that subtle model trimming influenced performance, with both models reaching 71% accuracy. These findings suggest that transformers may exhibit stronger feature selection capabilities compared to ResNet models, offering potential advantages in medical image analysis. </td>
      </tr>
    <tr>
        <td><img src="FoilNet.png" width="250" height="150"></td>
        <td>I was part of a research project focused on hydrofoil surfing, a unique form of surfing where riders use hydrofoils attached to their surfboards to navigate unbroken waves while hovering above the water's surface. Our research highlighted the increasing popularity of foiling, particularly the downwind technique that allows surfers to ride open ocean wind swells with the help of hydrofoil technology. Recognizing the challenge faced by novice users in identifying suitable waves for foiling, we introduced Foil-Net, a user-friendly wave classification tool that employs an autoencoder and convolutional neural network to categorize and assess waves for hydrofoil surfing based on their quality and suitability. <b>(Accepted ISVC 2023)</b> </td>
      </tr>
       <tr>
        <td><img src="7.png" width="250" height="150"></td>
        <td>The paper proposes a set of operations for manipulating general n-way trees, which are trees with each node containing data elements and up to n+1 children. B-trees are a special case of n-way trees that have additional restrictions. The proposed operations include makeSingle(), spliceAt(), splitDownAt(), and splitUpAt(), and they use the Composite State Design Pattern to define the child of an n-way tree as another n-way tree. The paper also presents an algorithm for constructing an n-way tree using another n-way tree as a parameter. <b>(SCCUR 2023)</b> </td>
      </tr>
    </table>

    <h2>In the Media</h2>
    <p>Check out the latest news articles featuring me:</p>
    <ul>
        <li><a href="https://seaver.pepperdine.edu/newsroom/articles/9-28-23-sean-wu.htm">Medical Applications for Large Language Models</a></li>
        <li><a href="https://seaver.pepperdine.edu/newsroom/articles/4-20-23-sean-wu-goldwater.htm">Winning Barry Goldwater Scholarship</a></li>
    </ul>

    
