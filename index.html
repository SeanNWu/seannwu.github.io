<!DOCTYPE html>
<head>
    <title>Sean Wu</title>
    <style>
      body {
        margin-left: 200px;
        margin-right: 200px;
      }

    </style>
  </head>
  <body>
     <h1 style="margin-top:20px; margin-bottom:20px;"></h1>
   <div style="text-align: center; display: flex; justify-content: center; align-items: center;">
      <img src="sean_img_final.JPG" width="400" height="328" class="profile">
    </div>


    <p> My name is Sean Wu, and I am an undergraduate student at Pepperdine studying computer science and mathematics. I am passionate about conducting research in the fields of deep learning and computer vision, with a particular interest in their application to medicine. I believe that technology has the power to revolutionize healthcare, and I am dedicated to contributing to the development of innovative solutions that can improve healthcare outcomes and diagnosis. I have been involved in various research projects, including developing a deep learning algorithm to diagnose glaucoma progression and conducting image analysis for computed tomography. I invite you to explore my portfolio and learn more about my projects and achievements.</p>
   
    <br>
    
    <h2>Awards and Honors</h2>
<table cellspacing="10">
  <tr>
    <td><img src="11.png" width="250" height="150"></td>
    <td>Named one of 413 Scholars out of estimated pool of over 5,000 college sophomores and juniors, highlighting exceptional aptitude and potential for a research career in natural sciences, engineering, and mathematics. See <a href="https://goldwaterscholarship.gov/">Goldwater Scholarship Website</a>.</td>
  </tr>
  <tr>
    <td><img src="10.png" width="250" height="150"></td>
    <td>This summer I'll be a research fellow at Amazon SURE @ Columbia University, where I'll be conducting research under Simon Billinge. Check out the program details here: <a href="https://www.amazon.science/sure">Amazon Science Website</a></td>
  </tr>
  <tr>
    <td><img src="keck.png" width="250" height="100"></td>
    <td>Last summer, I was a part of the Keck Scholars Fellows program at Pepperdine where I conducted research during both the school year and the summer.</td>
  </tr>
</table>
    
    
    <h2>Research Projects</h2>
    
    <h3>Deep Learning in Ophthalmology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="4.png" width="250" height="150"></td>
        <td>I was involved in study aimed to see if a deep learning model could predict visual field (VF) progression using pairs of optic disc photographs. We used 3,919 eyes and found that the model accurately predicted VF progression with an AUC of 0.862 and an accuracy of 81.0%. XRAI heat maps confirmed that the model was focusing on regions of the optic disc expected to show glaucomatous damage. These findings suggest that deep learning models can be useful in managing glaucoma. <b>(Presented at AGS 2023, Accepted to WGS, Submitted to JAMA Ophthalmology)</b></td>
      </tr>
      <tr>
        <td><img src="2.png" width="250" height="150"></td>
        <td>I lead a study that proposes a framework that uses auxiliary tasks to improve the accuracy of predicting glaucoma progression using a convolutional neural network. The framework utilizes patient age, mean deviation, and optical coherence tomography data to train the model. The study compares baseline models with no auxiliary outputs to the ones built using auxiliary tasks and observes a 6.5% increase in AUC-ROC in the final auxiliary-domain model. The proposed framework demonstrates the usefulness of auxiliary tasks when training ophthalmology models and leveraging important patient data that may not be readily available in routine clinical care. <b>(Under review for MICCAI 2023)</b></td>
      </tr>
      <tr>
        <td><img src="3.png" width="250" height="150"></td>
        <td>I was involved in a method to predict central 10° global and local visual field (VF) measurements using macular optical coherence tomography (OCT) volume scans with deep learning (DL). Our study included 1121 OCT volume scans and 10-2 VFs from 289 eyes (257 patients). We used macular scans to estimate 10-2 VF mean deviation (MD), threshold sensitivity (TS), and total deviation (TD) at 68 locations, and a 3D Convolutional Neural Network based on 3D DenseNet121 architecture was used for prediction. We compared DL predictions to those from broken-stick models (BM) and carried out 10-fold stratified cross-validation to optimize generalizability. The performance of DL and broken-stick models was compared based on correlations between ground truth and predicted VF measures and mean absolute error (MAE: ground truth-minus-predicted values). We found that macular OCT volume scans can be used to predict global central VF parameters with clinically relevant accuracy. <b>(TVST in revision)</b> </td>
      </tr>
        <tr>
        <td><img src="eye.png" width="250" height="150"></td>
        <td>In this research, I developed a deep learning approach for the segmentation of eyelid and iris contours to aid facial reconstructive surgeons. To standardize the dataset, I utilized a pre-trained eye detection algorithm to crop the patient's eyes and normalize magnification. A deep U-Net network was used for semantic segmentation, consisting of encoding and decoding layers. Data augmentation techniques were used to improve model generalization, and a DICE binary cross-entropy loss function was used to calculate the loss. Finally, two independent models were trained for eyelid and iris segmentation, respectively. The iris segmentation model aids in precise image registration before and after surgery. <b>(Submitted to ASOPRS 2023)</b></td>
      </tr>
      </tr>
        <tr>
        <td><img src="TPS.png" width="250" height="150"></td>
        <td> In my research project, I focused on tarsal plate contour segmentation in patient images. I utilized a deep neural network approach to learn the correlation between the raw input images and the tarsal plate contours. Specifically, I implemented a deep encoder-decoder U-Net with a pre-trained ResNet50 encoder to extract image features and generate a binary segmentation mask. The network was trained using a DICE binary cross entropy loss function, a learning rate of 1e-4, and a batch size of 2.  <b>(Submitted to ASOPRS 2023)</b></td>
      </tr>
       </tr>
        <tr>
        <td><img src="MMCR Figure.drawio.png" width="250" height="150"></td>
        <td> (Using Artificial Intelligence for Evaluating Structural Eyelid Change Following Mϋller’s Muscle-Conjunctival Resection) I developed a post-processing computer vision method to compare the results of plastic surgery patients before and after their procedures using iris registration techniques. I trained a deep neural network to analyze iris images and extract relevant features. Then, I employed iris registration techniques to align the pre-surgery and post-surgery iris images for accurate comparison. By comparing the extracted features, I was able to measure and quantify the changes in the patients' eyelid shape. This approach provides an objective and reliable method to assess the effectiveness of plastic surgery procedures based on the iris. <b>(Submitted to ASOPRS 2023)</b></td>
      </tr>
       <tr>
        <td><img src="ARVO.png" width="250" height="150"></td>
        <td>I was involved in a study that aimed to develop a deep learning (DL) model for predicting visual field (VF) progression in glaucoma patients using baseline optical coherence tomography (OCT) and serial optic disc photographs (ODPs). The study analyzed the data of 3,081 eyes from 1,646 patients with glaucoma or glaucoma suspect, with an average follow-up time of 7.8 (4.7) and 10.3 (5.1) years for stable and progressing eyes, respectively. The results showed that VF progression was detected in 29% of eyes and the mean time to progression in the progressing group was 6.8 (4.2) years. The DL model with baseline OCT and serial ODPs had a high accuracy in predicting VF progression years ahead of time. This model may have clinical implications for earlier detection of glaucoma progression. <b>(Accepted to ARVO 2023)</b></td>
      </tr>
       <tr>
        <td><img src="vf.png" width="250" height="150"></td>
        <td>I conducted research on a deep survival analysis algorithm to predict future glaucoma progression and time to detect progression (TTP) from early visual field (VF) information using a deep learning (DL) model. The TTP was the date of the two consecutive visits. I designed a DL model to predict glaucoma progression from the threshold sensitivities at the 54 points of the first five VF visits. I paired a survival analysis with the DL model for predicting the TTP. The results showed that the mean of TTP was 3.4 years, the AUC for predicting future glaucoma progression was 0.81, and the R squared and mean absolute error between the actual and predicted TTP were 0.92 and 0.73 years, respectively. <b>(Submitted to AAO 2023)</b></td>
      </tr>
       <tr>
        <td><img src="ODP.png" width="250" height="150"></td>
        <td>I participated in a research project that aimed to design a deep learning model for predicting the progression of glaucoma using a multimodal approach. I collaborated with other researchers to utilize a convolutional neural network pre-trained on ImageNet and incorporated baseline structural measures including disc photographs, retinal nerve fiber layer, and macular OCT measures as predictors. By combining all three imaging modalities, our model achieved a significantly higher performance for predicting progression with an AUC of 0.884 [0.834-0.934]. <b>(Submitted to AAO 2023)</b></td>
      </tr>
       <tr>
        <td><img src="gen.png" width="250" height="150"></td>
        <td>The research project I worked on aimed to predict final visual field measurements using a deep learning model. We analyzed data from 7,150 glaucoma eyes with 5 or more VF visits and ≥3 years of follow-up, and developed a generative DL model that predicted mean deviation, pattern standard deviation, and threshold sensitivities at 54 VF locations using data from the first five VF exams. Our goal was to improve the prediction of final VF measurements and ultimately aid in the diagnosis and management of glaucoma. <b>(Submitted to AAO 2023)</b></td>
      </tr>
    </table>
    
    <h3>Artificial Intelligence in Ecology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="6.png" width="250" height="150"></td>
        <td>I developed an automated process for classifying plant cells based on their type to expedite analysis and broaden the scope of questions that can be asked in anatomical studies of plant hydraulic traits. Our research evaluated a deep learning-based model that leveraged both cropped cell image input and contextual information from broader cropped images to accurately segregate plant cells. We found that using a second image input significantly improved the model's accuracy (98.1%), highlighting the importance of local context in accurately classifying cells. Our results suggest that this classifier could have future applications in automatic cell-type detection in xylem tissue image cross-sections. <b>(ISVC 2023)</b></td>
      </tr>
      <tr>
        <td><img src="PlantSeg.png" width="250" height="150"></td>
        <td>In this project, I constructed a deep convolutional neural network (DCNN) to segment and classify cell types in light micrographs. I created an encoder-decoder U-Net architecture using convolutional layers to encode features and transposed convolutional layers to upscale features to a vessel segmentation mask. I interleaved batch normalization and max pooling layers to provide strong regularization. For classification, I explored transformers and convolutional neural networks and achieved a 98.1% accuracy. The testing samples were isolated, and the DCNN performed vessel segmentation with high pixel classification accuracy (97.05%) and excellent precision score (80.71%). <b>(ESA 2023)</b> </td>
      </tr>
    </table>
    
    <h3>Natural Language Processing</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="neph.jpeg" width="250" height="150"></td>
        <td>I am conducting a study on the development of an AI Nephrology Specialist using large language models. Specifically, I am fine-tuning a recent Alpaca model created by Stanford University using GPT-3 and Facebook's LLAMA. This study aims to improve the accuracy and efficiency of diagnosing and treating kidney diseases using machine learning algorithms. By training the AI Nephrology Specialist on vast amounts of medical data, we hope to provide healthcare professionals with a powerful tool for early detection and treatment of kidney diseases, ultimately leading to better patient outcomes.</td>
      </tr>

    </table>
    
    <h3>Interventional Neurology</h3>
    <table cellspacing="10">
      <tr>
        <td><img src="1.png" width="250" height="150"></td>
        <td>This is an ongoing paper that presents an innovative approach to perform a 2D to 3D reconstruction of Biplane DSA. I am proposing a Deep Neural Network (DNN) that can learn the mapping function between a pair of DSA images and a 3D surface mesh. This study uses various CNN encoders and output dimensions to explore the optimal design of the model. The outputted dimensions include two n x 3 dimensional vectors and a multi-output CNN with three independent fully connected layers. The performance of the model was evaluated using Chamfer Distance, and the results indicate that the proposed DNN can accurately predict the faces and vertices of the angiogram. The study also highlights the benefits of bypassing the surface reconstruction step by parameterizing the ground truth into two arrays of vertices and faces that can be directly utilized by radiologists.</td>
      </tr>
    </table>
    
    <h3>Others</h3>
 <table cellspacing="10">
      <tr>
        <td><img src="8.png" width="250" height="150"></td>
        <td>I co-lead research on the use of deep neural networks and transformer networks in medical imaging, specifically in determining salient regions. To address this challenge, I explored the application of dictionary learning theory as a potential solution. My study involved analyzing the Big Healthy Brains (BHB) dataset, which contains T1 MRI brain images from 10 healthy sites. Through comparisons with Grad-CAM and other visualizations, I found that my approach was more quantitative and precise in identifying subtle salient features that are likely utilized by ResNet and Vision Transformers models. Overall, my work demonstrated the potential for using dictionary learning theory in medical imaging to enhance the accuracy and effectiveness of deep learning models.</td>
      </tr>
       <tr>
        <td><img src="7.png" width="250" height="150"></td>
        <td>The paper proposes a set of operations for manipulating general n-way trees, which are trees with each node containing data elements and up to n+1 children. B-trees are a special case of n-way trees that have additional restrictions. The proposed operations include makeSingle(), spliceAt(), splitDownAt(), and splitUpAt(), and they use the Composite State Design Pattern to define the child of an n-way tree as another n-way tree. The paper also presents an algorithm for constructing an n-way tree using another n-way tree as a parameter. <b>(SCCUR 2023)</b> </td>
      </tr>
    </table>
    
